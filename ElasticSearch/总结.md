## ElasticSearch

### Lucecne

是一套信息检索工具包，jar包，不包含搜索引擎系统

包含：索引结构，读写索引的工具，排序，搜索规则，工具类。。。

### ElasticSearch简介

es是一个实时分布式搜索和分析引擎，他让你以前所未有的速度处理大数据成为可能

它用于**全文搜索**、**结构化搜索**、**分析**以及将这三者混合使用

### Solr简介

Solr是Apache下的一个顶级开源项目，采用java开发，他是基于Lucene的全文搜索服务器。Solr可独立运行，可以运行在Jetty、Tomcat等。Solr索引的实现方法很简单，用POST方法向Solr服务器发送一个描述Field及其内容的XML文档，Slor根据xml文档添加、删除、更新索引。Solr搜索只需要发送HTPP GET请求，然后对Solr返回xml、json等格式的查询结果进行解析，组织页面布局。Solr搜索只需要发送HTTP GET请求，然后对Solr返回XML、json等格式的查询结果进行解析，组织页面布局。Solr不提供构建UI的功能，Solr提供了一个管理界面，通过管理界面可以查询Solr的配置和运行情况

### ElasticSearch和Solr总结

1. es基本是开箱即用 ，非常简单，Solr安装略微复杂一丢丢
2. Solr利用Zookeeper进行分布式管理，而ElasticSearch自身带有分布式协调管理功能
3. Solr支持更多格式的数据，比如JSON\XML\CSV，而es仅支持json文件格式
4. Solr官方提供的功能更多，而es本身更注重于核心功能，高级功能多由第三方插件提供，例如图形化界面需要kibana友好支撑
5. Solr查询快，但更新索引时慢（即插入删除慢），用于电商等查询多的应用
    * ES建立索引快（查询慢），即实时查询快，用facebook新浪等搜索
    * Solr是传统搜索应用的有力解决方案，但ES更适用于新兴的实时搜索应用
6. Solr比较成熟，有一个更大、更成熟的用户、开发和贡献者社区，而ES相对开发维护者较少，更新较快，学习使用成本高

### SlasticSearch安装

####  window下安装

解压就可以使用

![1606394597635](H:\Notes\ElasticSearch\upload\1606394597635.png)

目录

```
bin 启动文件
config 配置文件
	log4j2 日志配置文件
	jvm.options java虚拟机相关的配置
	elasticsearch.yml elasticsearch的配置文件，默认端口9200  跨域
lib 相关jar包
logs 日志
modules 功能模块
plugins 插件 ik
```

ElasticSearch Head安装谷歌插件

配置es

```yml
http:
  cors:
    enabled : true
    allow-origin : "*"
```

## 核心概念

### ES核心概念

ES是面向文档，关系行数据库和elasticsearch客观的对比![image-20201207144229939](H:\Notes\ElasticSearch\upload\image-20201207144229939.png)

elasticsearch（集群）中可以包含多个索引（数据库），每个索引中可以包含多个类型（表），每个类型下又包含多个文档（行），每个文档中又包含多个字段（列）

### 物理设计

es在后台把每个索引分成多个分片，每分分片可以在集群中的不同服务器间迁移。

一个人就是一个集群，默认的集群名称就是elasticsearch

### 逻辑设计

一个索引类型中，包含多个文档，比如说文档1，文档2。当我们索引一篇文档时，可以通过这样的一个顺序找到他：索引->类型->文档ID。通过这个组合我们就能索引到某个具体的文档。注意ID不必是整数，实际上他是个字符串

### 文档

之前说es是面向文档的，那么就意味着索引和所搜索数据的最小单位是文档，es中，文档有几个重要属性

* 自我包含，一篇文档同时包含字段和对应的值，也就是同时包含key：value
* 可以是层次型的， 一个文档中包含自文档，复杂的逻辑就是这么来的
* 灵活的结构，文档不依赖预先定义的模式，我们知道关系型数据库中，要提前定义字段才能使用，在es中，对于字段是非常灵活的，有时候，我们可以忽略该字段，或者动态的添加一个新字段

尽管我们可以随意的新增或者忽略某个字段，但是，每个字段的类型非常重要，比如一个年龄字段类型，可以是字符串也可以是整型，因为es会保存字段和类型之间的映射及其他的设置。这种映射具体到每个映射的每种类型，这也是为什么在es中，类型有时候也称为映射类型。

###  类型

类型是文档的逻辑容器，就像关系型数据库一样，表格是行的容器。类型中对于字段的定义称为映射，比如name映射为字符串类型。我们说文档是无模式的，他们不需要拥有映射中所定义的所有字段，比如新增一个字段，那么es是怎么做的呢？es会自动的将新字段加入映射，但是这个字段的不确定他是什么类型，es就开始猜，如果这个值是18，那么es会认为他是整形。但是es也可能猜不对，所以最安全的方式就是提前定义好需要的映射，这点跟关系型数据库殊途同归了，先定义好字段，然后再使用，别整什么幺蛾子

### 索引

就是数据库

索引是映射类型的容器，es中的索引是一个非常强大的文档合集。索引存储了映射类型的字段和其他设置。探后他们被存储到了各个分片上。我们来研究下分片是如何工作的

#### 物理设计：节点和分片如何工作

一个集群至少有一个节点，而一个节点就是一个es进程，节点可以有多个索引默认的，如果你创建索引，那么索引将会有5个分片（primary shard， 又称主分片）构成的，每一个主分片会有一个副本（replica shard， 又称复制分片）

![image-20201207160623745](H:\Notes\ElasticSearch\upload\image-20201207160623745.png)

上图是一个有3个节点的集群，可以看到主分片和对应的复制分片都不会在同一个节点内，这样有利于某个节点挂掉了，数据也不至于丢失。实际上，一个分片是一个lucene索引，一个包含==倒排索引==的文件目录，倒排索引的结构使得es在不扫描全部文档的情况下，就能告诉你哪些文档包含特定的关键字。

#### 倒排索引

es使用的是一种称为倒排索引的结构，采用lucene倒排索引作为底层。这种结构使用与快速的全文搜索，一个索引由文档中所有不重复的列表构成，对于每一个词，都有一个包含他的文档列表。例如：现在有两个文档，每个文档包含如下内容

```
good good study day#文档1包含的内容
hello good world day#文档2包含的内容
```

为了创建倒排索引，我们首先要将每个文档拆分成独立的词（或称为词条或者tokens），然后创建一个包含所有不重复的词条的排序列表，然后列出每个词条出现在哪个文档

| term  | doc_1 | doc_2 |
| :---: | :---: | :---: |
| good  |   √   |   √   |
| study |   √   |   ×   |
|  day  |   √   |   √   |
| hello |   ×   |   √   |
| world |   ×   |   √   |

现在我们试图搜索good study，只需要查看包含每个词条的文档 score

| term  | dac_1 | doc_2 |
| :---: | :---: | :---: |
| good  |   √   |   √   |
| study |   √   |   ×   |
| total |   2   |   1   |

两个文档都匹配，但是第一个文档比第二个匹配程度更高。如果没有别的条件，现在，这两个包含关键字的文档都将返回。

#### es索引和lucene索引的对比

在es中，索引这个词被频繁使用，这就是术语的使用。在es中，索引被分为多个片段，每份分片是一个lucene的索引。所以==一个es索引是由多个luence索引组成的==

elasticsearch-plugin可以通过这个命令来查看加载进来的插件

![image-20201207165808460](H:\Notes\ElasticSearch\upload\image-20201207165808460.png)

## 操作

rest风格是一种架构风格，而不是标准，只是提供了一组设计原则和约束条件。他主要用于客户端和服务器交互类的软件。基于这个风格设计的软件可以更简洁，更有层次，更易于实现缓存等机制

| method |       url(localhost:9200+)        |          描述          |
| :----: | :-------------------------------: | :--------------------: |
|  PUT   |     /索引名称/类型名称/文档id     | 创建文档（指定文档id） |
|  POST  |        /索引名称/类型名称         | 创建文档（随机文档id） |
|  POST  | /索引名称/类型名称/文档id/_update |        修改文档        |
| DELETE |     /索引名称/类型名称/文档id     |        删除文档        |
|  GET   |     /索引名称/类型名称/文档id     |   通过文档id查询文档   |
|  POST  |    /索引名称/类型名称/_search     |      查询所有数据      |

### 关于索引的基本操作

#### 创建索引

1. 创建一个索引

    ```json
    PUT /test1/type1/1
    {
      "name": "你是谁",
      "age": 20
    }
    ```

2. 创建成功

    <img src="H:\Notes\ElasticSearch\upload\image-20201208142308367.png" alt="image-20201208142308367" style="zoom: 50%;" />

    自动增加索引，数据也成功的添加了。类似于数据库

3. name这个字段也要指定类型，毕竟我们是关系型数据库，是需要指定类型的。

    * 字符串类型

        text、keyword（不可分割）

    * 数值类型

        long、integer、short、byte、double、float、half float、scaled float

    * 日期类型

        date

    * 布尔值类型

        boolean

    * 二进制类型

        binary

    * 等等

4. 指定字段的类型

    ```json
    PUT /test2
    {
      "mappings": {
        "properties": {
          "name": {
            "type": "text"
          }, 
          "age": {
            "type": "integer"
          },
          "birthday": {
            "type": "date"
          }
        }
      }
    }
    ```

    查看这个规则的具体信息(GET 索引)

    ```json
    {
      "test2" : {
        "aliases" : { },
        "mappings" : {
          "properties" : {
            "age" : {
              "type" : "integer"
            },
            "birthday" : {
              "type" : "date"
            },
            "name" : {
              "type" : "text"
            }
          }
        },
        "settings" : {
          "index" : {
            "creation_date" : "1607409129699",
            "number_of_shards" : "1",
            "number_of_replicas" : "1",
            "uuid" : "CeI1or_rST6JP1vw3LDYug",
            "version" : {
              "created" : "7060099"
            },
            "provided_name" : "test2"
          }
        }
      }
    }
    ```

    <img src="H:\Notes\ElasticSearch\upload\image-20201208144424219.png" alt="image-20201208144424219" style="zoom: 50%;" />

    如果自己的文档字段没有指定，那么es就会给我们配置默认字段类型

    扩展：通过命令elasticsearch查看索引情况

    ```
    GET _cat/*  #可以获得es当前的很多信息
    ```

#### 修改信息

1. 可以使用PUT修改，然后覆盖

    ```json
    PUT /test3/_doc/1
    {
      "name":"栾云平",
      "age": 36,
      "birth":"1984-03-20"
    }
    ```

    ```json
    {
      "_index" : "test3",
      "_type" : "_doc",
      "_id" : "1",
      "_version" : 2, //version变成了2
      "result" : "updated",
      "_shards" : {
        "total" : 2,
        "successful" : 1,
        "failed" : 0
      },
      "_seq_no" : 1,
      "_primary_term" : 1
    }
    ```

2. 通过POST+update修改

    ```json
    POST /test3/_doc/1/_update
    {
      "doc":{
        "name":"高栾是真的"
      }
    }
    ```

#### 删除索引

通过DELETE命令实现删除、根据你的请求来判断是删除索引还是删除文档记录

使用RESTFUL风格是ES推荐大家使用的

### 关于文档的基本操作

#### 基本操作

1. 添加数据 PUT

    ```json
    PUT /lyp/user/1  //ID要改，不然就不是添加，而是修改
    {
      "name":"栾云平",
      "age":23,
      "desc":"相声界扛把子",
      "tags":["怼怼", "直男","脾气"]
    }
    ```

2. 获取数据 GET

    ```json
    GET lyp/user/1
    ```

3. 更新数据 PUT

    ```json
    {
      "_index" : "lyp",
      "_type" : "user",
      "_id" : "3",
      "_version" : 2, // 版本
      "result" : "updated", // 操作
      "_shards" : {
        "total" : 2,
        "successful" : 1,
        "failed" : 0
      },
      "_seq_no" : 6,
      "_primary_term" : 1
    }
    ```

4. POST _update 推荐使用这种更新方式

    ```json
    PUT /lyp/user/3
    {
      "doc":{
        "age": 37
      }
    }
    POST /lyp/user/3/_update
    {
      "doc":{
        "age": 36
      }
    }
    ```

5. 简单的搜索

    ```json
    GET lyp/user/_search?q=name:栾云平
    ```

    简单的条件查询，可以根据默认的映射规则，产生基本的查询

#### 复杂查询

```json
//查询的参数体使用json结构
GET lyp/user/_search
{
  "query":{
    "match": {
      "name": "栾云"
    }
  }
}
```

结果：

```json
#! Deprecation: [types removal] Specifying types in search requests is deprecated.
{
  "took" : 2,
  "timed_out" : false,
  "_shards" : {
    "total" : 1,
    "successful" : 1,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : { //hit索引和文档的信息
    "total" : { 
      "value" : 3,//查询的结果总数
      "relation" : "eq"
    },
    "max_score" : 1.2008023,//最大分数，我们可以通过分数来判断谁更加符合结果
    //查询出来的具体文档，遍历数据中的东西
    "hits" : [
      {
        "_index" : "lyp",
        "_type" : "user",
        "_id" : "1",
        "_score" : 1.2008023,
        "_source" : {
          "name" : "栾云平",
          "age" : 23,
          "desc" : "相声界扛把子",
          "tags" : [
            "怼怼",
            "直男",
            "脾气"
          ]
        }
      },
      {
        "_index" : "lyp",
        "_type" : "user",
        "_id" : "4",
        "_score" : 0.977973,
        "_source" : {
          "name" : "栾云平高峰",
          "age" : 23,
          "desc" : "相声界扛把子",
          "tags" : [
            "怼怼",
            "直男",
            "脾气"
          ]
        }
      },
      {
        "_index" : "lyp",
        "_type" : "user",
        "_id" : "5",
        "_score" : 0.977973,
        "_source" : {
          "name" : "栾云平爱徒",
          "age" : 23,
          "desc" : "相声界扛把子",
          "tags" : [
            "怼怼",
            "直男",
            "脾气"
          ]
        }
      }
    ]
  }
}
```

结果过滤

```json
"_source": ["name", "desc"]
```

排序

```json
//通过哪个字段进行排序
"sort": [
    {
        "age": {
            "order": "desc"
        }
    }
]
```

分页

```json
"from": 0, //从第几个数据开始
"size": 1  //返回多少条数据
//数据下标从0开始
```

布尔值查询

must：下列的所有条件都要符合

should：只要满足下面任何条件一个都行

must_not：不满足以下条件的人（多个条件都不满足）

```json
GET lyp/user/_search
{
  "query": {
    "bool": {
      "must": [
        {
          "match": {
            "name": "栾云平"
          }
        },
        {
          "match": {
            "age": "23"
          }
        }
      ]
    }
  }
}
```

过滤

```json
POST lyp/_search
{
  "query": {
    "bool": {
      "filter": {
        "range": {
          "age": {
            "gte": 10,
            "lt": 55555
          }
        }
      }
    }
  }
}
/**
gt 大于
lt 小于
gte 大于等于
lte 小于等于
*/
```

匹配多个条件

```json
GET lyp/user/_search
{
  "query": {
    "match": {
      "tags": "好 有"
    }
  }
}
/*
多个条件使用空格隔开
只要满足其中一个结果就可以被查询出来
这个时候可以通过分值进行基本的判断
*/
```

固定分数

```json
POST lyp/_search
{
  "query": {
    "constant_score": {
      "filter": {
        "match":{
          "name":"栾云"
        }
      },
      "boost":1.1
    }
  }
}
```

精确查询

term查询是直接通过倒排索引指定的词条进行进程精确查找的

##### 关于分词

* term：直接查询精确的
* match：会使用分词器解析（先分析文档，然后再通过分析的文档进行查询)

两个类型：text keyword

```json
GET _analyze
{
  "analyzer": "keyword",//当成关键字去分析，不会被分词器解析
  "text": "陈豪是傻逼 java name"
}
GET _analyze
{
  "analyzer": "standard",
  "text": "陈豪是傻逼 java name"
}
```

多个值匹配精确查询

```json
GET testdb/_search
{
  "query": {
    "bool": {
      "should": [
        {
          "term": {
            "t1": "22"
          }
        },
        {
          "term": {
            "t1": "33"
          }
        }
      ]
    }
  }
}
```

高亮查询

```json
"highlight": {
    //自定义搜索高亮条件
    "pre_tags": "<p class='key' style='color:red'>", 
    "post_tags": "</p>", 
    "fields": {
      "name":{}
    }
  }
```

## ik分词器

ik分词器插件

分词：即把一段中文或者别的划分成一个个的关键字，我们再搜索时候会把自己的信息进行分词，会把数据库中或者索引库中的数据进行分词，然后进行一个匹配操作，默认的中文分词器是将每个字看成一个词，比如：“就这水平”会被分成“就”“这”“水”“平”。这显然是不符合要求的，所以我们需要安装中文分词器ik来解决这个问题

ik提供了两个分词算法：ik_smart和ik_max_word，其中ik_smart为最少切分，ik_max_word为最细粒度划分。

ik_smart为最少切分

<img src="H:\Notes\ElasticSearch\upload\image-20201208131747560.png" alt="image-20201208131747560" style="zoom:33%;" />

ik_max_word为最细粒度划分，穷尽词库的可能

<img src="H:\Notes\ElasticSearch\upload\image-20201208131814853.png" alt="image-20201208131814853" style="zoom: 33%;" />

发现问题：“傻逼”被拆开了

这种自己需要的词，需要我们自己加到我们的分词器的字典里

在分词器的config目录下，添加一个*.dic文件(文件编码需要为UTF-8)，在里面每一行写上一个词，然后在IKAnalyzer.cfg.xml里面添加这个文件

```xml
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE properties SYSTEM "http://java.sun.com/dtd/properties.dtd">
<properties>
	<comment>IK Analyzer 扩展配置</comment>
	<!--用户可以在这里配置自己的扩展字典 -->
	<entry key="ext_dict">hl.dic</entry>
	 <!--用户可以在这里配置自己的扩展停止词字典-->
	<entry key="ext_stopwords"></entry>
	<!--用户可以在这里配置远程扩展字典 -->
	<!-- <entry key="remote_ext_dict">words_location</entry> -->
	<!--用户可以在这里配置远程扩展停止词字典-->
	<!-- <entry key="remote_ext_stopwords">words_location</entry> -->
</properties>
```

重启es

```shell
[INFO ][o.w.a.d.Monitor          ] [FAKE-ANDROID] [Dict Loading] H:\elasticsearch\elasticsearch-7.6.0\plugins\ik\config\hl.dic
```

## SpringBoot整合

1. 找到原生依赖

    ```xml
    <dependency>
    	<groupId>org.elasticsearch.client</groupId>
        <artifactId>elasticsearch-rest-high-level-client</artifactId>
        <version>7.6.0</version>
    </dependency>
    ```

2. 找对象

    ```java
    @Bean
    public RestHighLevelClient restHighLevelClient(){
    RestHighLevelClient restHighLevelClient = new RestHighLevelClient(
            RestClient.builder(
                new HttpHost("localhost", 9200, "http")
            )
        );
        return restHighLevelClient;
    }
    ```

    
